{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "From \"Practical Introduction to Web Scraping in Python\"\n",
    "by Colin OKeefe at www.realpython.com\n",
    "Only necessary code for getting the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Importing-libraries\" data-toc-modified-id=\"Importing-libraries-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Importing libraries</a></span></li><li><span><a href=\"#Making-Web-Requests\" data-toc-modified-id=\"Making-Web-Requests-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Making Web Requests</a></span></li><li><span><a href=\"#Wrangling-HTML-with-BeautifulSoup\" data-toc-modified-id=\"Wrangling-HTML-with-BeautifulSoup-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Wrangling HTML with BeautifulSoup</a></span></li><li><span><a href=\"#Putting-All-Together\" data-toc-modified-id=\"Putting-All-Together-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Putting All Together</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-16T06:10:10.487507Z",
     "start_time": "2019-04-16T06:10:09.900007Z"
    }
   },
   "outputs": [],
   "source": [
    "from requests import get\n",
    "from requests.exceptions import RequestException\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import date, datetime, timedelta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making Web Requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-16T06:10:10.520007Z",
     "start_time": "2019-04-16T06:10:10.490007Z"
    }
   },
   "outputs": [],
   "source": [
    "# function prepared to download web pages\n",
    "def simple_get(url):\n",
    "    \"\"\"\n",
    "    Function attempts to get the content at 'url' by making an HTTP GET request.\n",
    "    If the content-type of response is a kind of HTML/XML,\n",
    "    it will return the text content, otherwise return None.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        resp = get(url)\n",
    "        if is_good_response(resp):\n",
    "            return resp.content\n",
    "        else:\n",
    "            return None\n",
    "            \n",
    "    except RequestException as e:\n",
    "        log_error('Error during requests to {0} : {1}'.format(url, str(e)))\n",
    "        return None\n",
    "    \n",
    "# function checking the answer to the request\n",
    "def is_good_response(resp):\n",
    "    \"\"\"\n",
    "    Returns True if the response seems to be HTML, False otherwise.\n",
    "    \"\"\"\n",
    "    content_type = resp.headers['Content-Type'].lower()\n",
    "    return (resp.status_code == 200\n",
    "           and content_type is not None\n",
    "           and content_type.find('html') > -1)\n",
    "\n",
    "# function printing error message if web downloading was unsuccessful\n",
    "def log_error(e):\n",
    "    \"\"\"\n",
    "    It is always a good idea to log errors.\n",
    "    This function just prints them, but you can make it\n",
    "    do anything.\n",
    "    \"\"\"\n",
    "    #print(e)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wrangling HTML with BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-16T06:10:10.572007Z",
     "start_time": "2019-04-16T06:10:10.523507Z"
    }
   },
   "outputs": [],
   "source": [
    "# function extracting a single list of names\n",
    "def get_names():\n",
    "    \"\"\"\n",
    "    Downloads the page where the list of mathematicians is found\n",
    "    and returns a list of strings, one per mathematician.\n",
    "    \"\"\"\n",
    "    url = 'http://www.fabpedigree.com/james/mathmen.htm'\n",
    "    response = simple_get(url)\n",
    "    \n",
    "    if response is not None:\n",
    "        html = BeautifulSoup(response, 'html.parser')\n",
    "        names = set() # there are no repeated elements\n",
    "        for li in html.select('li'):\n",
    "            for name in li.text.split('\\n'):\n",
    "                if len(name) > 0:\n",
    "                    names.add(name.strip())\n",
    "                    \n",
    "    return list(names)\n",
    "\n",
    "    # raising an exception if a failure to get any data from the url\n",
    "    raise Exception('Error retrieving contents at {}'.format(url))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-16T06:10:10.634507Z",
     "start_time": "2019-04-16T06:10:10.574507Z"
    }
   },
   "outputs": [],
   "source": [
    "# function returns 'popularity score' - the pageviews number for each name\n",
    "# viewed on Wiki(all statistics are on xtools.wmflabs.org)\n",
    "\n",
    "def get_hits_on_name(name):\n",
    "    \"\"\"\n",
    "    Accepts a name of the mathematician and returns the number\n",
    "    of hist that mathematician's Wikipedia page received in the\n",
    "    last 60 days, as an 'int'.\n",
    "    # function returns 'popularity score' - the pageviews number for each name\n",
    "    \"\"\"\n",
    "   \n",
    "    now = date.today()\n",
    "    start_day = now - timedelta(60)\n",
    "    now, start_day = [datetime.strftime(elm, '%Y%m%d') for elm in [now, start_day]]\n",
    "\n",
    "    # using API method 'pageviews with given name to loop over singular days(in 'items') and get hit results of the last 60 days\n",
    "    url = f'https://wikimedia.org/api/rest_v1/metrics/pageviews/per-article/en.wikipedia/all-access/all-agents/{name}/daily/{start_day}/{now}'\n",
    "    response = get(url).json()\n",
    "    if response is not None:\n",
    "        if 'title' in response.keys():\n",
    "            log_error('No pageviews found for {}'.format(name))\n",
    "            return None \n",
    "        else:\n",
    "            result = sum([x['views'] for x in response['items']])\n",
    "            return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Putting All Together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-16T06:10:44.476781Z",
     "start_time": "2019-04-16T06:10:10.809507Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting the list of names...\n",
      "... done.\n",
      "\n",
      "Getting stats for each name\n",
      "... done.\n",
      "\n",
      "\n",
      "The most popular mathematicians are:\n",
      "\n",
      "Albert Einstein with 1165493 pageviews\n",
      "Isaac Newton with 525051 pageviews\n",
      "Aristotle with 403253 pageviews\n",
      "Galileo Galilei with 376890 pageviews\n",
      "Srinivasa Ramanujan with 285146 pageviews\n",
      "\n",
      "But we did not find results for 28 mathematicians on the list\n"
     ]
    }
   ],
   "source": [
    "# the goal of the code is finding out which mathematician is\n",
    "# most beloved by the public (no by ranking but by views) and \n",
    "# next to sort the names by popularity\n",
    "if __name__ == '__main__':\n",
    "    print('Getting the list of names...')\n",
    "    names = get_names()\n",
    "    print('... done.\\n')\n",
    "    results = []\n",
    "    \n",
    "    print('Getting stats for each name')\n",
    "    for name in names:\n",
    "        try:\n",
    "            hits = get_hits_on_name(name)\n",
    "            if hits is None:\n",
    "                hits = -1\n",
    "                        \n",
    "            results.append((hits, name))\n",
    "        except:\n",
    "            results.append((-1, name))\n",
    "            log_error('Error encountered while processing {}, skipping'.format(name))\n",
    "            \n",
    "    print('... done.\\n')\n",
    "\n",
    "    results.sort()\n",
    "    results.reverse()\n",
    "    \n",
    "    if len(results) > 5:\n",
    "        top_marks = results[:5]\n",
    "    else:\n",
    "        top_marks = results\n",
    "        \n",
    "    print('\\nThe most popular mathematicians are:\\n')\n",
    "    for (mark, mathematician) in top_marks:\n",
    "        print('{} with {} pageviews'.format(mathematician, mark))\n",
    "    no_results = len([res for res in results if res[0] == -1])\n",
    "    print('\\nBut we did not find results for {} mathematicians on the list'.format(no_results))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "The results are not correct in 100% because of some differences between strings of names from 'http://www.fabpedigree.com/james/mathmen.htm' page and those counterparts in Wikipedia. Some manually (?) cleaning would help but.... "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
